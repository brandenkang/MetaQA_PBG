{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main working file\n",
    "from torchbiggraph.eval import do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import h5py\n",
    "import torch\n",
    "import random \n",
    "from pathlib import Path\n",
    "from torchbiggraph.config import parse_config\n",
    "from torchbiggraph.converters.importers import TSVEdgelistReader, convert_input_data\n",
    "from torchbiggraph.train import train\n",
    "from torchbiggraph.util import SubprocessInitializer, setup_logging\n",
    "from torchbiggraph.model import DotComparator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8930f4e724a54d4b8620e6dad3f8b730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "80000\n",
      "3468\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = 'data/example_2'\n",
    "GRAPH_PATH = DATA_DIR + '/edges.tsv'\n",
    "TRAINING_PATH = DATA_DIR + '/training.tsv'\n",
    "TEST_PATH = DATA_DIR + '/test.tsv'\n",
    "MODEL_DIR = 'model_2'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        shutil.rmtree('data')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        shutil.rmtree('model_2')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# ==================================================================\n",
    "# 0. PREPARE THE GRAPH\n",
    "# the result of this step is a single file 'data/example_2/graph.tsv'\n",
    "# ==================================================================\n",
    "\n",
    "# This the graph we will be embedding.\n",
    "# It has 10 types of nodes, or entities, and 9 types of edges, or relationships. \n",
    "    test_edges = []\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    check_entities = []\n",
    "\n",
    "    count=0\n",
    "    count2=0\n",
    "    \n",
    "#     with open('kb.txt', 'r') as f: \n",
    "#         for line in f: \n",
    "#            line=line.rstrip().split(\"|\")\n",
    "#            line[0] = line[0].split(\" \")\n",
    "#            line[0] = \"_\".join(line[0])\n",
    "#         #    line[2] = line[2].split(\" \")\n",
    "#         #    line[2] = \"_\".join(line[2])\n",
    "#            test_edges.append(line)\n",
    "#            count+=1\n",
    "#            if count == 134741:\n",
    "#                break\n",
    "\n",
    "    with open('kb.txt', 'r' ) as f:\n",
    "        for line in tqdm(f):\n",
    "           line=line.rstrip().split(\"|\")\n",
    "           line[0] = line[0].split(\" \")\n",
    "           line[0] = \"_\".join(line[0])\n",
    "           count2 +=1 \n",
    "           if count2 <= 80000:\n",
    "               train_data.append(line)\n",
    "               check_entities.append(line[0])\n",
    "               check_entities.append(line[1])\n",
    "               check_entities.append(line[2])\n",
    "           elif count2 > 80000:\n",
    "               if line[0] in check_entities and line[1] in check_entities and line[2] in check_entities:\n",
    "                    test_data.append(line) \n",
    "\n",
    "    print(len(train_data))\n",
    "    print(len(test_data))\n",
    "\n",
    "    # split_index = len(test_edges) // 1.25  \n",
    "    # training_edges = test_edges[:split_index]\n",
    "    # split_edges = test_edges[split_index:]\n",
    "\n",
    "\n",
    "#     os.makedirs(DATA_DIR, exist_ok=True)\n",
    "#     with open(GRAPH_PATH, 'w') as f:\n",
    "#         for edge in test_edges:\n",
    "#             f.write('\\t'.join(edge) + '\\n')\n",
    "\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    with open(TRAINING_PATH, 'w') as f:\n",
    "        for edge in train_data:\n",
    "            f.write('\\t'.join(edge) + '\\n')    \n",
    "            \n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    with open(TEST_PATH, 'w') as f:\n",
    "        for edge in test_data:\n",
    "            f.write('\\t'.join(edge) + '\\n')    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80000 training \n",
    "# 3468 test \n",
    "\n",
    "# # 1. DEFINE CONFIG\n",
    "# # this dictionary will be used in steps 2. and 3.\n",
    "# # ==================================================\n",
    "\n",
    "raw_config = dict(\n",
    "    # I/O data\n",
    "    entity_path=DATA_DIR,\n",
    "    edge_paths=[\n",
    "        DATA_DIR + '/training',\n",
    "        DATA_DIR + '/test'\n",
    "    ],\n",
    "    checkpoint_path=MODEL_DIR,\n",
    "    # Graph structure\n",
    "    entities={\n",
    "        \"movie\": {\"num_partitions\": 1},\n",
    "        \"director\": {\"num_partitions\": 1},\n",
    "        \"writer\": {\"num_partitions\": 1},\n",
    "        \"starred_actor\": {\"num_partitions\": 1},\n",
    "        \"year\": {\"num_partitions\": 1},\n",
    "        \"language\": {\"num_partitions\": 1},\n",
    "        \"tags\": {\"num_partitions\": 1},\n",
    "        \"genre\": {\"num_partitions\": 1}, \n",
    "        \"votes\": {\"num_partitions\":1}, \n",
    "        \"rating\": {\"num_partitions\":1}\n",
    "    },\n",
    "    relations=[\n",
    "        {\n",
    "            \"name\": \"directed_by\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"director\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"written_by\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"writer\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"starred_actors\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"starred_actor\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"release_year\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"year\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"in_language\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"language\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"has_tags\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"tags\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },            \n",
    "        {\n",
    "            \"name\": \"has_genre\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"genre\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"has_imdb_votes\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"votes\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"has_imdb_rating\",\n",
    "            \"lhs\": \"movie\",\n",
    "            \"rhs\": \"rating\",\n",
    "            \"operator\": \"complex_diagonal\",\n",
    "        }\n",
    "\n",
    "    ],\n",
    "\n",
    "    dynamic_relations=False,\n",
    "    dimension=50,  \n",
    "    global_emb=False,\n",
    "    comparator=\"dot\",\n",
    "    num_epochs=7,\n",
    "    num_uniform_negs=1000,\n",
    "    loss_fn=\"softmax\",\n",
    "    lr=0.1,\n",
    "    regularization_coef=1e-3,\n",
    "    eval_fraction=0.,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found some files that indicate that the input data has already been preprocessed, not doing it again.\n",
      "These files are in: data/example_2, data/example_2/training, data/example_2/test\n"
     ]
    }
   ],
   "source": [
    "# =================================================\n",
    "# 2. TRANSFORM GRAPH TO A BIGGRAPH-FRIENDLY FORMAT\n",
    "# This step generates the following metadata files:\n",
    "\n",
    "# data/example_2/entity_count_director_0.txt\n",
    "# data/example_2/entity_count_genre_0.txt\n",
    "\n",
    "# data/example_2/entity_count_director_0.json\n",
    "# data/example_2/entity_count_genre_0.json\n",
    "\n",
    "# and this file with data:\n",
    "# data/example_2/edges_partitioned/edges_0_0.h5\n",
    "# =================================================\n",
    "setup_logging()\n",
    "config = parse_config(raw_config)\n",
    "subprocess_init = SubprocessInitializer()\n",
    "# input_edge_paths = [Path(GRAPH_PATH)]\n",
    "# training_edge_paths = [Path(TRAINING_PATH)]\n",
    "# test_edge_paths = [Path(TEST_PATH)]\n",
    "input_edge_paths = [Path(TRAINING_PATH),Path(TEST_PATH)]\n",
    "output_train_path, output_test_path = config.edge_paths\n",
    "\n",
    "convert_input_data(\n",
    "    config.entities,\n",
    "    config.relations,\n",
    "    config.entity_path,\n",
    "    config.edge_paths,\n",
    "    input_edge_paths,\n",
    "    TSVEdgelistReader(lhs_col=0, rel_col=1, rhs_col=2),\n",
    "    dynamic_relations=config.dynamic_relations,\n",
    ")\n",
    "\n",
    "# ===============================================\n",
    "# 3. TRAIN THE EMBEDDINGS\n",
    "# files generated in this step:\n",
    "\n",
    "# checkpoint_version.txt\n",
    "# config.json\n",
    "# embeddings_director_0.v7.h5\n",
    "# embeddings_genre_0.v7.h5\n",
    "# embeddings_language_0.v7.h5\n",
    "# embeddings_movie_0.v7.h5\n",
    "# embeddings_rating_0.v7.h5\n",
    "# embeddings_starred_actor_0.v7.h5\n",
    "# embeddings_tags_0.v7.h5\n",
    "# embeddings_votes_0.v7.h5\n",
    "# embeddings_writer_0.v7.h5\n",
    "# embeddings_year_0.v7.h5\n",
    "\n",
    "# model.v7.h5\n",
    "# training_stats.json\n",
    "# ===============================================\n",
    "train_config = attr.evolve(config, edge_paths=[output_train_path])\n",
    "eval_config = attr.evolve(config, edge_paths = [output_test_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-10 14:38:13,988   [Trainer-0] Loading entity counts...\n",
      "2020-12-10 14:38:14,153   [Trainer-0] Creating workers...\n",
      "2020-12-10 14:38:14,482   [Trainer-0] Initializing global model...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiRelationEmbedder:\n\tsize mismatch for rhs_operators.0.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.0.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.1.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.1.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.2.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.2.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.3.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.3.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.4.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.4.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.5.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.5.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.6.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.6.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.7.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.7.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.8.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.8.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-b64e434c1b4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprocess_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchbiggraph/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config, model, trainer, evaluator, rank, subprocess_init)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mGPUTrainingCoordinator\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mTrainingCoordinator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mcoordinator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoordinatorT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprocess_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchbiggraph/train_cpu.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, model, trainer, evaluator, rank, subprocess_init, stats_handler)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadpath_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_read_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptim_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiRelationEmbedder:\n\tsize mismatch for rhs_operators.0.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.0.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.1.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.1.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.2.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.2.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.3.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.3.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.4.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.4.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.5.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.5.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.6.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.6.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.7.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.7.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.8.real: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50]).\n\tsize mismatch for rhs_operators.8.imag: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([50])."
     ]
    }
   ],
   "source": [
    "## here\n",
    "train(train_config, subprocess_init=subprocess_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-10 01:52:52,939   [Evaluator] Starting edge path 1 / 1 (data/example_2/test)\n",
      "2020-12-10 01:52:56,930   [Evaluator] ( 0 , 0 ): Processed 3468 edges in 3.9 s (0.0009M/sec); load time: 0.11 s\n",
      "2020-12-10 01:52:56,938   [Evaluator] Stats for edge path 1 / 1, bucket ( 0 , 0 ): loss:  17.606 , pos_rank:  333.3 , mrr:  0.0781969 , r1:  0.0428201 , r10:  0.136967 , r50:  0.243224 , auc:  0.678057 , count:  3468\n",
      "2020-12-10 01:52:56,941   [Evaluator] \n",
      "2020-12-10 01:52:56,942   [Evaluator] Stats for edge path 1 / 1: loss:  17.606 , pos_rank:  333.3 , mrr:  0.0781969 , r1:  0.0428201 , r10:  0.136967 , r50:  0.243224 , auc:  0.678057 , count:  3468\n",
      "2020-12-10 01:52:56,943   [Evaluator] \n",
      "2020-12-10 01:52:56,945   [Evaluator] \n",
      "2020-12-10 01:52:56,946   [Evaluator] Stats: loss:  17.606 , pos_rank:  333.3 , mrr:  0.0781969 , r1:  0.0428201 , r10:  0.136967 , r50:  0.243224 , auc:  0.678057 , count:  3468\n",
      "2020-12-10 01:52:56,947   [Evaluator] \n"
     ]
    }
   ],
   "source": [
    "do_eval(eval_config, subprocess_init=subprocess_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # =======================================================================\n",
    "#     # 4. LOAD THE EMBEDDINGS\n",
    "#     # The final output of the process consists of a dictionary mapping each entity to its embedding\n",
    "\n",
    "#     # =======================================================================\n",
    "\n",
    "#     # entities_path = DATA_DIR + '/entity_names_entities_0.json'\n",
    "\n",
    "#     # entities_emb_path = MODEL_DIR + \"/embeddings_entities.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#     #     .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     # with open(entities_path, 'r') as f:\n",
    "#     #     entities = json.load(f)\n",
    "\n",
    "#     # with h5py.File(entities_emb_path, 'r') as g:\n",
    "#     #     entity_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     # entity2embedding = dict(zip(entities, entity_embeddings))\n",
    "#     # print('entity embeddings')\n",
    "#     # print(entity2embedding)\n",
    "\n",
    "#     movies_path = DATA_DIR + '/entity_names_movie_0.json'\n",
    "#     directors_path = DATA_DIR + '/entity_names_director_0.json'\n",
    "#     writers_path = DATA_DIR + '/entity_names_writer_0.json'\n",
    "#     actors_path = DATA_DIR + '/entity_names_starred_actor_0.json'\n",
    "#     years_path = DATA_DIR + '/entity_names_year_0.json'\n",
    "#     languages_path = DATA_DIR + '/entity_names_language_0.json'\n",
    "#     tags_path = DATA_DIR + '/entity_names_tags_0.json'\n",
    "#     genres_path = DATA_DIR + '/entity_names_genre_0.json'\n",
    "#     votes_path = DATA_DIR + '/entity_names_votes_0.json'\n",
    "#     rating_path = DATA_DIR + '/entity_names_rating_0.json'\n",
    "\n",
    "\n",
    "#     movie_emb_path = MODEL_DIR + \"/embeddings_movie_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     director_emb_path = MODEL_DIR + \"/embeddings_director_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     writer_emb_path = MODEL_DIR + \"/embeddings_writer_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "    \n",
    "#     actor_emb_path = MODEL_DIR + \"/embeddings_starred_actor_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     year_emb_path = MODEL_DIR + \"/embeddings_year_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "    \n",
    "#     language_emb_path = MODEL_DIR + \"/embeddings_language_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "    \n",
    "#     tags_emb_path = MODEL_DIR + \"/embeddings_tags_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     genre_emb_path = MODEL_DIR + \"/embeddings_genre_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     votes_emb_path = MODEL_DIR + \"/embeddings_votes_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     rating_emb_path = MODEL_DIR + \"/embeddings_rating_0.v{NUMBER_OF_EPOCHS}.h5\" \\\n",
    "#         .format(NUMBER_OF_EPOCHS=raw_config['num_epochs'])\n",
    "\n",
    "#     with open(movies_path, 'r') as f:\n",
    "#         movies = json.load(f)\n",
    "\n",
    "#     with h5py.File(movie_emb_path, 'r') as g:\n",
    "#         movie_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     movie2embedding = dict(zip(movies, movie_embeddings))\n",
    "#     # print('movie embeddings')\n",
    "#     # print(movie2embedding)\n",
    "\n",
    "#     with open(directors_path, 'r') as f:\n",
    "#         directors = json.load(f)\n",
    "\n",
    "#     with h5py.File(director_emb_path, 'r') as g:\n",
    "#         director_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     director2embedding = dict(zip(directors, director_embeddings))\n",
    "#     # print('director embeddings')\n",
    "#     # print(director2embedding)\n",
    "\n",
    "#     with open(writers_path, 'r') as f:\n",
    "#         writers = json.load(f)\n",
    "\n",
    "#     with h5py.File(writer_emb_path, 'r') as g:\n",
    "#         writer_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     writer2embedding = dict(zip(writers, writer_embeddings))\n",
    "#     # print('writer embeddings')\n",
    "#     # print(writer2embedding)\n",
    "\n",
    "#     with open(actors_path, 'r') as f:\n",
    "#         actors = json.load(f)\n",
    "\n",
    "#     with h5py.File(actor_emb_path, 'r') as g:\n",
    "#         actor_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     actor2embedding = dict(zip(actors, actor_embeddings))\n",
    "#     # print('actor embeddings')\n",
    "#     # print(actor2embedding)\n",
    "\n",
    "#     with open(years_path, 'r') as f:\n",
    "#         years = json.load(f)\n",
    "\n",
    "#     with h5py.File(year_emb_path, 'r') as g:\n",
    "#         year_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     year2embedding = dict(zip(years, year_embeddings))\n",
    "#     # print('year embeddings')\n",
    "#     # print(year2embedding)\n",
    "\n",
    "#     with open(languages_path, 'r') as f:\n",
    "#         languages = json.load(f)\n",
    "\n",
    "#     with h5py.File(language_emb_path, 'r') as g:\n",
    "#         language_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     language2embedding = dict(zip(languages, language_embeddings))\n",
    "#     # print('language embeddings')\n",
    "#     # print(language2embedding)\n",
    "\n",
    "#     with open(tags_path, 'r') as f:\n",
    "#         tags = json.load(f)\n",
    "\n",
    "#     with h5py.File(tags_emb_path, 'r') as g:\n",
    "#         tags_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     tag2embedding = dict(zip(tags, tags_embeddings))\n",
    "#     # print('tag embeddings')\n",
    "#     # print(tag2embedding)\n",
    "\n",
    "#     with open(genres_path, 'r') as f:\n",
    "#         genres = json.load(f)\n",
    "\n",
    "#     with h5py.File(genre_emb_path, 'r') as g:\n",
    "#         genre_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     genre2embedding = dict(zip(genres, genre_embeddings))\n",
    "#     # print('genre embeddings')\n",
    "#     # print(genre2embedding)\n",
    "\n",
    "#     with open(votes_path, 'r') as f:\n",
    "#         votes = json.load(f)\n",
    "\n",
    "#     with h5py.File(votes_emb_path, 'r') as g:\n",
    "#         votes_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     votes2embedding = dict(zip(votes, votes_embeddings))\n",
    "#     # print('votes embeddings')\n",
    "#     # print(votes2embedding)\n",
    "\n",
    "#     with open(rating_path, 'r') as f:\n",
    "#         ratings = json.load(f)\n",
    "\n",
    "#     with h5py.File(rating_emb_path, 'r') as g:\n",
    "#         rating_embeddings = g['embeddings'][:]\n",
    "\n",
    "#     rating2embedding = dict(zip(ratings, rating_embeddings))\n",
    "#     # print('rating embeddings')\n",
    "#     # print(rating2embedding)\n",
    "\n",
    "#     entity2embedding = {**movie2embedding, **director2embedding, **writer2embedding, **actor2embedding, **year2embedding, **language2embedding, **tag2embedding, **genre2embedding, **votes2embedding, **rating2embedding}\n",
    "#     print('entity embeddings')\n",
    "#     print(entity2embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #########################################################################\n",
    "\n",
    "# # # Load count of dynamic relations\n",
    "# # with open(\"data/FB15k/dynamic_rel_count.txt\", \"rt\") as tf:\n",
    "# #     dynamic_rel_count = int(tf.read().strip())\n",
    "\n",
    "# # # Load the operator's state dict\n",
    "# # with h5py.File(\"model/fb15k/model.v50.h5\", \"r\") as hf:\n",
    "# #     operator_state_dict = {\n",
    "# #         \"real\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/real\"][...]),\n",
    "# #         \"imag\": torch.from_numpy(hf[\"model/relations/0/operator/rhs/imag\"][...]),\n",
    "# #     }\n",
    "\n",
    "# # operator = ComplexDiagonalDynamicOperator(400, dynamic_rel_count)\n",
    "# # operator.load_state_dict(operator_state_dict)\n",
    "# # comparator = DotComparator()\n",
    "\n",
    "# # # Load the names of the entities, ordered by offset.\n",
    "# # with open(\"data/FB15k/entity_names_all_0.json\", \"rt\") as tf:\n",
    "# #     entity_names = json.load(tf)\n",
    "# # src_entity_offset = entity_names.index(\"/m/0f8l9c\")  # France\n",
    "# # dest_entity_offset = entity_names.index(\"/m/05qtj\")  # Paris\n",
    "\n",
    "# # # Load the names of the relation types, ordered by index.\n",
    "# # with open(\"data/FB15k/dynamic_rel_names.json\", \"rt\") as tf:\n",
    "# #     rel_type_names = json.load(tf)\n",
    "# # rel_type_index = rel_type_names.index(\"/location/country/capital\")\n",
    "\n",
    "# # # Load the trained embeddings\n",
    "# # with h5py.File(\"model/fb15k/embeddings_all_0.v50.h5\", \"r\") as hf:\n",
    "# #     src_embedding = torch.from_numpy(hf[\"embeddings\"][src_entity_offset, :])\n",
    "# #     dest_embedding = torch.from_numpy(hf[\"embeddings\"][dest_entity_offset, :])\n",
    "\n",
    "# # # Calculate the scores\n",
    "# # scores, _, _ = comparator(\n",
    "# #     comparator.prepare(src_embedding.view(1, 1, 400)),\n",
    "# #     comparator.prepare(\n",
    "# #         operator(\n",
    "# #             dest_embedding.view(1, 400),\n",
    "# #             torch.tensor([rel_type_index]),\n",
    "# #         ).view(1, 1, 400),\n",
    "# #     ),\n",
    "# #     torch.empty(1, 0, 400),  # Left-hand side negatives, not needed\n",
    "# #     torch.empty(1, 0, 400),  # Right-hand side negatives, not needed\n",
    "# # )\n",
    "\n",
    "# # print(scores)\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "# # print(\"Now let's do some simple things within torch:\")\n",
    "\n",
    "# # src_entity_offset = dictionary[\"entities\"][\"user_id\"].index(\"0\")  # France\n",
    "# # dest_1_entity_offset = dictionary[\"entities\"][\"user_id\"].index(\"7\")  # Paris\n",
    "# # dest_2_entity_offset = dictionary[\"entities\"][\"user_id\"].index(\"1\")  # Paris\n",
    "# # rel_type_index = dictionary[\"relations\"].index(\"follow\") # note we only have one...\n",
    "\n",
    "# # with h5py.File(\"model/example_2/embeddings_user_id_0.v10.h5\", \"r\") as hf:\n",
    "# #     src_embedding = hf[\"embeddings\"][src_entity_offset, :]\n",
    "# #     dest_1_embedding = hf[\"embeddings\"][dest_1_entity_offset, :]\n",
    "# #     dest_2_embedding = hf[\"embeddings\"][dest_2_entity_offset, :]\n",
    "# #     dest_embeddings = hf[\"embeddings\"][...]\n",
    "\n",
    "\n",
    "# comparator = DotComparator()\n",
    "\n",
    "# scores_1, _, _ = comparator(\n",
    "#     comparator.prepare(torch.tensor(movie_embeddings.reshape([1,1,10]))),\n",
    "#     comparator.prepare(torch.tensor(director_embeddings.reshape([1,1,10]))),\n",
    "#     torch.empty(1, 0, 10),  # Left-hand side negatives, not needed\n",
    "#     torch.empty(1, 0, 10),  # Right-hand side negatives, not needed\n",
    "# )\n",
    "\n",
    "# scores_2, _, _ = comparator(\n",
    "#     comparator.prepare(torch.tensor(movie_embeddings.reshape([1,1,10]))),\n",
    "#     comparator.prepare(torch.tensor(actor_embeddings.reshape([1,1,10]))),\n",
    "#     torch.empty(1, 0, 10),  # Left-hand side negatives, not needed\n",
    "#     torch.empty(1, 0, 10),  # Right-hand side negatives, not needed\n",
    "# )\n",
    "\n",
    "# print(scores_1)\n",
    "# print(scores_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
